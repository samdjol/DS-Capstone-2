


import numpy as np
import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', lambda x: f'{x:,.2f}')

import matplotlib.pyplot as plt
import seaborn as sns

import glob
import os
import warnings
import joblib

from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score, roc_curve, confusion_matrix
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.compose import ColumnTransformer

from xgboost import XGBRegressor


path = '../Data'

csv_files = glob.glob(path + "/*.csv")
to_remove = ['../Data/game_lineups.csv',
             '../Data/game_events.csv'
            ]
csv_files = [x for x in csv_files if x not in to_remove]

# Create an empty dictionary to store the DataFrames
dataframes = {}

for file in csv_files:
  # Get the base name of the file
  base_name = os.path.basename(file)
  
  # Remove the .csv extension to get the clean name
  # and add '_df' to match your requested format
  df_name = f"{os.path.splitext(base_name)[0]}_df"
  
  # Read the csv and add it to the dictionary
  dataframes[df_name] = pd.read_csv(file)

print("Available DataFrames:", list(dataframes.keys()))


# Unpack the dictionary into separate global variables
for name, df in dataframes.items():
  globals()[name] = df


competitions_df.head()


for name, df_object in dataframes.items():
    print(f"--- Analyzing: {name} ---")
    print("Head:")
    print(df_object.head())
    print("\nInfo:")
    df_object.info()
    print("\nDescribe:")
    print(df_object.describe())
    print("\n" + "="*50 + "\n")


#Dropping unsued columns
players_df.drop(columns = ['first_name', 'last_name','player_code', 'image_url', 'url'], inplace = True)
competitions_df.drop(columns = ['competition_code','sub_type', 'url'], inplace=True)
clubs_df.drop(columns = ['filename', 'url'], inplace=True)


for name, df_object in dataframes.items():
    print(f"--- Null Rows for {name} ---")
    null_rows = df_object[df_object.isnull().any(axis=1)]
    print(null_rows)





appearances_df.dropna(inplace=True)


players_df.head()


players_df.info()


players_df.isnull().sum()


# Create a boolean mask where the condition is True
mask = players_df['country_of_birth'] == players_df['country_of_citizenship']

# Sum the True values (since True=1, False=0) to get the count
count = mask.sum()

print(f"Number of rows where birth country equals citizenship: {count}")


players_df['country_of_birth'] = players_df['country_of_birth'].fillna(players_df['country_of_citizenship'])


players_df.isnull().sum()


players_df = players_df.dropna(subset=['country_of_birth', 'country_of_citizenship'])


players_df['country_of_birth'][players_df['city_of_birth'].isna()].value_counts()





players_df = players_df.drop(columns=['city_of_birth'])


players_df['position'][players_df['sub_position'].isna()].value_counts()


players_df = players_df.dropna(subset=['position', 'sub_position'])


players_df = players_df.dropna(subset=['date_of_birth'])


players_df['sub_position'][players_df['foot'].isna()].value_counts()


players_df['foot'].value_counts()


# Group by 'foot' and calculate the mean of the highest market value
avg_value_by_foot = players_df.groupby('foot')['highest_market_value_in_eur'].mean().reset_index()

# Sort the values for a cleaner plot
avg_value_by_foot = avg_value_by_foot.sort_values('highest_market_value_in_eur', ascending=False)


# --- Plotting ---
plt.figure(figsize=(8, 6))
sns.barplot(x='foot', y='highest_market_value_in_eur', data=avg_value_by_foot)

plt.title('Average Highest Market Value by Preferred Foot', fontsize=16)
plt.xlabel('Preferred Foot', fontsize=12)
plt.ylabel('Average Highest Market Value (in EUR)', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()


avg_value_by_foot


#too many values to drop, going to impute 'unknown' cat
players_df['foot'] = players_df['foot'].fillna('Unknown')


#height_in_cm can be replaced with averages. 
#Since players' positions can be a good indicator of height, we'll use average by sub_position
imputed_height = players_df.groupby('sub_position')['height_in_cm'].transform('mean')

# Fill the NaN values in the original column using this new series
players_df['height_in_cm'] = players_df['height_in_cm'].fillna(imputed_height)


# Get today's date
today = pd.to_datetime('today')

# Ensure the contract expiration date column is in datetime format
players_df['contract_expiration_date'] = pd.to_datetime(players_df['contract_expiration_date'])


# --- 1. Feature Engineering: Calculate Contract Days Remaining ---
# Create a new feature for the number of days left on the contract from today
players_df['contract_days_remaining'] = (players_df['contract_expiration_date'] - today).dt.days


# --- 2. Handle the Missing Values ---

# Step A: Create a binary flag for missing contract data
players_df['contract_info_missing'] = players_df['contract_days_remaining'].isnull().astype(int)


# Step B: Impute the missing values in the 'contract_days_remaining' column
# Filling with the median is a robust choice
median_contract_days = players_df['contract_days_remaining'].median()
players_df['contract_days_remaining'] = players_df['contract_days_remaining'].fillna(median_contract_days)


# Drop the original, less useful date column.
players_df = players_df.drop(columns=['contract_expiration_date'])

players_df.head()


players_df['agent_name'] = players_df['agent_name'].fillna('Unknown')


players_df.isnull().sum()





players_df = players_df.drop(columns=['highest_market_value_in_eur'])


players_df = players_df.dropna(subset=['market_value_in_eur'])


players_df.head()





appearances_df.head()


#Get totals for stats from appearances_df
sum_cols = ['yellow_cards', 'red_cards', 'goals', 'assists', 'minutes_played']

player_stats = appearances_df.groupby('player_id')[sum_cols].sum()
players_df = pd.merge(players_df, player_stats, on='player_id', how='left')
players_df[sum_cols] = players_df[sum_cols].fillna(0)


players_df.sort_values('goals', ascending=False).head()


players_df['date_of_birth'] = pd.to_datetime(players_df['date_of_birth'])


players_df['age_in_days'] = (today - players_df['date_of_birth']).dt.days
players_df = players_df.drop(columns=['date_of_birth'])


players_df.columns


num_cols = [
    'height_in_cm', 'market_value_in_eur', 'contract_days_remaining', 
    'yellow_cards', 'red_cards', 'goals','assists', 'minutes_played', 
    'age_in_days'
]

cat_cols = [
    'current_club_id','country_of_birth', 'country_of_citizenship',
    'sub_position', 'position', 'foot', 'agent_name',
    'current_club_domestic_competition_id', 'current_club_name', 
    'contract_info_missing'
]

for col in num_cols:
    plt.figure(figsize=(10, 6))
    sns.histplot(players_df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col.replace("_", " ").title()}', fontsize=16)
    plt.xlabel(col.replace("_", " ").title(), fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.grid(True)
    plt.show()


plt.figure(figsize=(10, 6))
sns.boxplot(x=np.log1p(players_df['market_value_in_eur'])) 
plt.title('Log Market Value in EUR', fontsize=16)
plt.grid(True)
plt.show()


for col in cat_cols:

    top_categories = players_df[col].value_counts().nlargest(10).index
    
    plt.figure(figsize=(12, 7))
    sns.countplot(y=col, data=players_df, order=top_categories)
    plt.title(f'Frequency of Top 10 Categories in {col.replace("_", " ").title()}', fontsize=16)
    plt.xlabel('Count', fontsize=12)
    plt.ylabel(col.replace("_", " ").title(), fontsize=12)
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    plt.show()


corr_matrix = players_df[num_cols].corr()

plt.figure(figsize=(12, 10))

sns.heatmap(
    corr_matrix, 
    annot=True,    
    cmap='coolwarm',
    fmt=".2f"       
)

plt.title('Correlation Matrix of Numerical Features', fontsize=16)
plt.show()






model_df = players_df.drop(columns=['player_id', 'name', 'last_season','current_club_id'])


model_df = model_df.drop(columns=['agent_name'])


X = model_df.drop('market_value_in_eur', axis=1)
y = model_df['market_value_in_eur']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def fit_evaluate_and_tune_model(X_train, X_test, y_train, y_test, model_class, num_cols, cat_cols, log_transform_target=False):
    """
    Trains, evaluates, and optionally tunes a model using pre-split data.

    Args:
        X_train, X_test, y_train, y_test: The pre-split training and testing data.
        model_class: The model class to be used.
        num_cols (list): List of numerical column names.
        cat_cols (list): List of categorical column names.
        log_transform_target (bool): If True, applies a log(1+x) transform to the target.

    Returns:
        tuple: The final (best) pipeline and its test scores (R-squared, RMSE).
    """
    
    # --- Set up a more robust warning filter ---
    warnings.filterwarnings("ignore", category=UserWarning, message=".*Found unknown categories.*")
    warnings.filterwarnings("ignore", category=FutureWarning)

    try:
        # --- 1. Initial Setup ---
        # Make copies to avoid modifying the original dataframes passed to the function
        X_train_processed = X_train.copy()
        X_test_processed = X_test.copy()
        y_train_processed = y_train.copy()
        y_test_processed = y_test.copy()

        # --- Apply Log Transform if requested ---
        if log_transform_target:
            print("\nApplying log transform to the target variable.")
            y_train_processed = np.log1p(y_train_processed)
            y_test_processed = np.log1p(y_test_processed)
        
        # --- Data Validation Step ---
        for col in num_cols:
            if col in X_train_processed.columns:
                X_train_processed[col] = pd.to_numeric(X_train_processed[col], errors='coerce')
                X_test_processed[col] = pd.to_numeric(X_test_processed[col], errors='coerce')

        # --- 2. Define Preprocessing Pipeline ---
        numerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])
        categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))])
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numerical_transformer, num_cols),
                ('cat', categorical_transformer, cat_cols)
            ],
            remainder='drop'
        )
        
        # --- 3. Evaluate Default Model ---
        default_pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', model_class(random_state=42) if 'random_state' in model_class().get_params() else model_class())
        ])
        
        default_pipeline.fit(X_train_processed, y_train_processed)
        y_pred_test_default = default_pipeline.predict(X_test_processed)
        y_pred_train_default = default_pipeline.predict(X_train_processed)

        # --- Inverse transform predictions if target was logged ---
        y_test_eval = np.expm1(y_test_processed) if log_transform_target else y_test_processed
        y_pred_test_eval = np.expm1(y_pred_test_default) if log_transform_target else y_pred_test_default
        y_train_eval = np.expm1(y_train_processed) if log_transform_target else y_train_processed
        y_pred_train_eval = np.expm1(y_pred_train_default) if log_transform_target else y_pred_train_default

        r2_test_default = r2_score(y_test_eval, y_pred_test_eval)
        rmse_test_default = np.sqrt(mean_squared_error(y_test_eval, y_pred_test_eval))
        r2_train_default = r2_score(y_train_eval, y_pred_train_eval)
        rmse_train_default = np.sqrt(mean_squared_error(y_train_eval, y_pred_train_eval))
        
        print(f"\n--- Initial {model_class.__name__} Evaluation ---")
        print(f"R-squared on Test Data: {r2_test_default:.2f}")
        print(f"R-squared on Training Data: {r2_train_default:.2f}")
        print(f"RMSE on Test Data: {rmse_test_default:,.2f}")
        print(f"RMSE on Training Data: {rmse_train_default:,.2f}")

        final_pipeline = default_pipeline
        final_r2 = r2_test_default
        final_rmse = rmse_test_default

        # --- 4. Conditional Hyperparameter Tuning ---
        if model_class in [RandomForestRegressor, XGBRegressor]:
            print("\n--- Starting Hyperparameter Tuning ---")
            
            # Define Model-Specific Parameter Grids
            if model_class == RandomForestRegressor:
                param_dist = {
                    'regressor__n_estimators': [100, 200, 500], 'regressor__max_depth': [10, 20, 30, None],
                    'regressor__min_samples_leaf': [1, 2, 4], 'regressor__max_features': ['sqrt', 'log2']
                }
            elif model_class == XGBRegressor:
                param_dist = {
                    'regressor__n_estimators': [100, 500, 1000], 'regressor__max_depth': [3, 5, 7, 10],
                    'regressor__learning_rate': [0.01, 0.05, 0.1], 'regressor__min_child_weight': [1, 5, 10]
                }

            # Randomized Search
            random_search = RandomizedSearchCV(estimator=default_pipeline, param_distributions=param_dist, n_iter=25, cv=5, verbose=1, random_state=42, n_jobs=-2, scoring='neg_root_mean_squared_error')
            random_search.fit(X_train_processed, y_train_processed)
            print("\nBest parameters from Randomized Search:", random_search.best_params_)

            # Grid Search
            best_params = random_search.best_params_
            param_grid = {}
            for key, value in best_params.items():
                if key in ['regressor__n_estimators']:
                    step = max(100, int(value * 0.2))
                    param_grid[key] = sorted(list(set([value, max(50, value - step), value + step])))
                elif isinstance(value, int) and value > 0: # Ensure value is at least 1
                    # Ensure the lower bound is at least 1
                    lower_bound = max(1, value - 1)
                    param_grid[key] = [lower_bound, value, value + 1]
                elif isinstance(value, float):
                    lower_bound = max(0.0, value * 0.9)
                    upper_bound = min(1.0, value * 1.1)
                    param_grid[key] = [lower_bound, value, upper_bound]
                else:
                    param_grid[key] = [value]
            
            grid_search = GridSearchCV(estimator=default_pipeline, param_grid=param_grid, cv=5, verbose=1, n_jobs=-2, scoring='neg_root_mean_squared_error')
            grid_search.fit(X_train_processed, y_train_processed)
            print("\nBest parameters from Grid Search:", grid_search.best_params_)
            
            # Overwrite final results with the tuned model's performance
            final_pipeline = grid_search.best_estimator_
            y_pred_test_tuned = final_pipeline.predict(X_test_processed)
            y_pred_train_tuned = final_pipeline.predict(X_train_processed)
            
            # Inverse transform predictions if target was logged
            y_test_eval = np.expm1(y_test_processed) if log_transform_target else y_test_processed
            y_pred_test_tuned_eval = np.expm1(y_pred_test_tuned) if log_transform_target else y_pred_test_tuned
            y_train_eval = np.expm1(y_train_processed) if log_transform_target else y_train_processed
            y_pred_train_tuned_eval = np.expm1(y_pred_train_tuned) if log_transform_target else y_pred_train_tuned

            final_r2 = r2_score(y_test_eval, y_pred_test_tuned_eval)
            final_rmse = np.sqrt(mean_squared_error(y_test_eval, y_pred_test_tuned_eval))
            r2_train_tuned = r2_score(y_train_eval, y_pred_train_tuned_eval)
            rmse_train_tuned = np.sqrt(mean_squared_error(y_train_eval, y_pred_train_tuned_eval))
            
            print(f"\n--- Tuned {model_class.__name__} Evaluation ---")
            print(f"R-squared on Test Data: {final_r2:.2f}")
            print(f"R-squared on Training Data: {r2_train_tuned:.2f}")
            print(f"RMSE on Test Data: {final_rmse:,.2f}")
            print(f"RMSE on Training Data: {rmse_train_tuned:,.2f}")
            
        return final_pipeline, final_r2, final_rmse
    finally:
        warnings.resetwarnings()

# 1. Define feature lists
numerical_features = [
    'height_in_cm', 'contract_days_remaining', 'yellow_cards', 
    'red_cards', 'goals', 'assists', 'minutes_played', 'age_in_days'
]
categorical_features = [
    'country_of_birth', 'country_of_citizenship',
    'sub_position', 'position', 'foot',
    'current_club_domestic_competition_id', 'current_club_name', 
    'contract_info_missing'
]

# 2. Create the train-test split
X = model_df.drop('market_value_in_eur', axis=1)
y = model_df['market_value_in_eur']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 3. Run all experiments using the same data split
print("\n--- EXPERIMENT 1: MODELS WITH ORIGINAL TARGET ---")
lr_pipeline, lr_r2, lr_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, LinearRegression, numerical_features, categorical_features
)
rf_pipeline, rf_r2, rf_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, RandomForestRegressor, numerical_features, categorical_features
)
xgb_pipeline, xgb_r2, xgb_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features
)


print("\n--- EXPERIMENT 2: MODELS WITH LOG-TRANSFORMED TARGET ---")
lr_pipeline_log, lr_r2_log, lr_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, LinearRegression, numerical_features, categorical_features, log_transform_target=True
)
rf_pipeline_log, rf_r2_log, rf_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, RandomForestRegressor, numerical_features, categorical_features, log_transform_target=True
)
xgb_pipeline_log, xgb_r2_log, xgb_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=True
)











high_val_df = model_df[model_df['market_value_in_eur'] > 10000000]


model_df['market_value_in_eur'].mean(), model_df['market_value_in_eur'].std()


high_val_df['market_value_in_eur'].mean(), high_val_df['market_value_in_eur'].std()


X_2 = high_val_df.drop('market_value_in_eur', axis=1)
y_2 = high_val_df['market_value_in_eur']

X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)


xgb_pipeline2, xgb_r2, xgb_rmse2 = fit_evaluate_and_tune_model(X_train_2, X_test_2, y_train_2, y_test_2, XGBRegressor, numerical_features, categorical_features, log_transform_target=True)


#New model with market values showed decreased performance


# 1. Access the trained XGBoost model and the preprocessor from the pipeline
xgb_model = xgb_pipeline_log.named_steps['regressor']
preprocessor = xgb_pipeline_log.named_steps['preprocessor']

# 2. Get the feature names after all transformations (like one-hot encoding)
# This is crucial for matching the scores to the correct feature names
feature_names = preprocessor.get_feature_names_out()

# 3. Get the feature importance scores from the model
importances = xgb_model.feature_importances_

# 4. Create a pandas Series for easy viewing and sorting
feature_importance_series = pd.Series(importances, index=feature_names)

# 5. Sort the values to see the most important features at the top
print("--- Top 15 Most Important Features (from XGBoost) ---")
print(feature_importance_series.nlargest(15))


# --- 1. Prepare Data for Analysis --
# Make predictions on the test set
y_pred_log = xgb_pipeline_log.predict(X_test)

# Inverse transform predictions and actuals to their original euro scale
y_pred_eur = np.expm1(y_pred_log)
y_test_eur = y_test

# Create a new DataFrame for analysis to avoid SettingWithCopyWarning
analysis_df = X_test.copy()
analysis_df['actual_market_value'] = y_test_eur
analysis_df['predicted_market_value'] = y_pred_eur
analysis_df['residual_error'] = analysis_df['actual_market_value'] - analysis_df['predicted_market_value']

# Convert age back from days to years for easier interpretation
analysis_df['age'] = (analysis_df['age_in_days'] / 365.25).round(1)


# --- 2. Analyze the Residuals (Plotting) ---
# A residual plot shows the errors vs. a feature

plt.figure(figsize=(12, 7))
sns.scatterplot(x='age', y='residual_error', data=analysis_df, alpha=0.5)
plt.axhline(0, color='red', linestyle='--')
plt.title('Residual Error vs. Player Age', fontsize=16)
plt.xlabel('Player Age (Years)', fontsize=12)
plt.ylabel('Prediction Error (Actual - Predicted) in EUR', fontsize=12)
plt.grid(True)
plt.show()


# --- 3. Examine the Biggest Misses ---
analysis_df = analysis_df.merge(players_df[['name']], left_index=True, right_index=True, how='left')

# Sort by the absolute error to find the biggest misses overall
analysis_df['abs_error'] = analysis_df['residual_error'].abs()
biggest_misses = analysis_df.sort_values('abs_error', ascending=False)

# Display the top 20 biggest prediction errors
print("--- Top 20 Biggest Prediction Misses ---")
display_cols = ['name', 'age', 'actual_market_value', 'predicted_market_value', 'residual_error']
print(biggest_misses[display_cols].head(20))


print("\n--- Top 10 Players the Model UNDERESTIMATED (Predicted too low) ---")
print(biggest_misses.sort_values('residual_error', ascending=False)[display_cols].head(10))

print("\n--- Top 10 Players the Model OVERESTIMATED (Predicted too high) ---")
print(biggest_misses.sort_values('residual_error', ascending=True)[display_cols].head(10))


model_df.head()





appearances_df.head()


clubs_df.head()


#Here we are getting a history of all the clubs a player has played for
# Get club names and player_ids matched
apps_df = pd.merge(
    left=appearances_df[['player_id', 'player_club_id']], 
    right=clubs_df[['club_id']], 
    left_on='player_club_id', 
    right_on='club_id', 
    how='left'
)
apps_df = apps_df[['player_id', 'player_club_id']]

# Get unique clubs for each player before counting
unique_clubs_df = apps_df.drop_duplicates(subset=['player_id', 'player_club_id']).copy()

# Adds a column that counts the unique clubs for each player (1, 2, 3, etc.)
unique_clubs_df['club_number'] = unique_clubs_df.groupby('player_id').cumcount() + 1

# Transforms the data from a long to a wide format
club_history_df = unique_clubs_df.pivot(
    index='player_id', 
    columns='club_number', 
    values='player_club_id' 
)

# Renames the numbered columns while preserving the 'player_id' index name
club_history_df.columns = [f'club_{col}' for col in club_history_df.columns]
club_history_df.reset_index(inplace=True)

# Display the head of the FINAL DataFrame
club_history_df.head()


#Merge new df with model df
model2_df = players_df.drop(columns=['name', 'last_season','current_club_id', 'current_club_name'])

model2_df = pd.merge(
    left=model2_df, 
    right=club_history_df, 
    on= 'player_id',
    how='left'
)

model2_df.head()


#We can create a 'Age peak' metric for players centered around 27 years
# Convert age from days to years first
model2_df['age'] = model2_df['age_in_days'] / 365.25

# Create a feature that is low at the peak age (27) and higher for younger/older players
model2_df['age_peak_diff_sq'] = (model2_df['age'] - 27)**2


model2_df = model2_df.drop(columns=['age_in_days'])


#Lets create a per 90 minutes (one match) feature
model2_df['goals_per_90'] = (model2_df['goals'] * 90) / (model2_df['minutes_played'] + 1)
model2_df['assists_per_90'] = (model2_df['assists'] * 90) / (model2_df['minutes_played'] + 1)


club_games_df.head()


#Instead of just club IDs or names, lets count their wins to effectively create a rating for the clubs they have played for
wins_series = club_games_df.groupby('club_id')['is_win'].sum()
wins_series = pd.Series(wins_series, name='wins')
wins_series.index.name = 'club_id'

# Convert the wins Series to a dictionary for fast lookups
wins_dict = wins_series.to_dict()

# Get the list of columns to update (e.g., 'club_1', 'club_2', ...)
club_cols = [f'club_{i}' for i in range(1, 14)]

for col in club_cols:
    # Check if the column exists in your DataFrame
    if col in model2_df.columns:
        # Use .map() to replace the club ID with its win count
        model2_df[col] = model2_df[col].map(wins_dict)

# After mapping, any clubs not in wins_dict or original NaNs will be NaN, fill these with 0.
model2_df[club_cols] = model2_df[club_cols].fillna(0).astype(int)


model2_df.head()


appearances_df.head()


competitions_df.head()


games_df.head()


#We want to adjust the goals, assists, and minutes for players based on who they played against, i.e. weigh them based off the 'toughness' of the competition
stats_df = pd.merge(
    left=appearances_df, 
    right=games_df[['game_id', 'home_club_id', 'away_club_id']],
    on='game_id',
    how='left'
)
stats_df.head()


#Keep the opponent id
stats_df['Opp'] = np.where(
    stats_df['player_club_id'] == stats_df['home_club_id'],  # Condition
    stats_df['away_club_id'],                               # Value if True
    stats_df['home_club_id']                                # Value if False
)


stats_df = stats_df.drop(columns=['appearance_id', 'game_id', 'player_current_club_id', 'date', 'player_name', 'yellow_cards', 'red_cards', 'home_club_id', 'away_club_id'])


wins_df = wins_series.reset_index()


#Normalize wins before adjusting goals, etc
norm_scaler = MinMaxScaler()
wins_df['normal_wins'] = norm_scaler.fit_transform(win_df[['wins']])


wins_df.head()


#Merge on previous df
stats_df = pd.merge(
    left=stats_df, 
    right=wins_df[['club_id', 'normal_wins']],
    left_on='Opp',
    right_on='club_id',
    how='left'
)


#Create new cols for adjusted stats
cols = ['goals', 'assists', 'minutes_played']

for col in cols:
    stats_df[f'{col}_adjusted'] = stats_df['normal_wins'] * stats_df[col]


#Group before adding back to main df
weighted_stats = stats_df.groupby('player_id')[['normal_wins', 'goals_adjusted', 'assists_adjusted', 'minutes_played_adjusted']].sum()


weighted_stats = weighted_stats.reset_index()


weighted_stats


model2_df = pd.merge(
    left=model2_df, 
    right=weighted_stats,
    on='player_id',
    how='left'
)


model2_df.sort_values('goals_adjusted', ascending=False).head()


#Realized way down that I needed a copy for future use
model5_df = model2_df.copy()

#Drop unneeded cols
model2_df = model2_df.drop(columns=['player_id', 'agent_name'])


model2_df.head()


model2_df.columns


numerical_features = ['height_in_cm', 'contract_days_remaining', 'yellow_cards',
                      'goals', 'assists', 'minutes_played', 'red_cards', 'club_1', 
                      'club_2', 'club_3', 'club_4', 'club_5', 'club_6', 'club_7', 
                      'club_8', 'club_9', 'club_10', 'club_11', 'club_12', 
                      'club_13', 'age', 'age_peak_diff_sq', 'goals_per_90', 
                      'assists_per_90','goals_adjusted', 'assists_adjusted', 
                      'minutes_played_adjusted'
                     ]

categorical_features = ['country_of_birth', 'country_of_citizenship', 'sub_position', 
                        'position', 'foot', 'current_club_domestic_competition_id',
                        'contract_info_missing'
                       ]
                        
X = model2_df.drop('market_value_in_eur', axis=1)
y = model2_df['market_value_in_eur']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

xgb_pipeline3, xgb_r2, xgb_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=False
)

xgb_pipeline3_log, xgb_r2_log, xgb_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=True
)








# 1. Access the trained XGBoost model and the preprocessor from the pipeline
xgb_model = xgb_pipeline3_log.named_steps['regressor']
preprocessor = xgb_pipeline3_log.named_steps['preprocessor']

# 2. Get the feature names after all transformations (like one-hot encoding)
# This is crucial for matching the scores to the correct feature names
feature_names = preprocessor.get_feature_names_out()

# 3. Get the feature importance scores from the model
importances = xgb_model.feature_importances_

# 4. Create a pandas Series for easy viewing and sorting
feature_importance_series = pd.Series(importances, index=feature_names)

# 5. Sort the values to see the most important features at the top
print("--- Top 15 Most Important Features (from XGBoost) ---")
print(feature_importance_series.nlargest(15))

# --- 1. Prepare Data for Analysis --
# Make predictions on the test set
y_pred_log = xgb_pipeline3_log.predict(X_test)

# Inverse transform predictions and actuals to their original euro scale
y_pred_eur = np.expm1(y_pred_log)
y_test_eur = y_test

# Create a new DataFrame for analysis to avoid SettingWithCopyWarning
analysis_df = X_test.copy()
analysis_df['actual_market_value'] = y_test_eur
analysis_df['predicted_market_value'] = y_pred_eur
analysis_df['residual_error'] = analysis_df['actual_market_value'] - analysis_df['predicted_market_value']


# --- 2. Analyze the Residuals (Plotting) ---
# A residual plot shows the errors vs. a feature

plt.figure(figsize=(12, 7))
sns.scatterplot(x='age', y='residual_error', data=analysis_df, alpha=0.5)
plt.axhline(0, color='red', linestyle='--')
plt.title('Residual Error vs. Player Age', fontsize=16)
plt.xlabel('Player Age (Years)', fontsize=12)
plt.ylabel('Prediction Error (Actual - Predicted) in EUR', fontsize=12)
plt.grid(True)
plt.show()


# --- 3. Examine the Biggest Misses ---
analysis_df = analysis_df.merge(players_df[['name']], left_index=True, right_index=True, how='left')

# Sort by the absolute error to find the biggest misses overall
analysis_df['abs_error'] = analysis_df['residual_error'].abs()
biggest_misses = analysis_df.sort_values('abs_error', ascending=False)

# Display the top 20 biggest prediction errors
print("--- Top 20 Biggest Prediction Misses ---")
display_cols = ['name', 'age', 'actual_market_value', 'predicted_market_value', 'residual_error']
print(biggest_misses[display_cols].head(20))


print("\n--- Top 10 Players the Model UNDERESTIMATED (Predicted too low) ---")
print(biggest_misses.sort_values('residual_error', ascending=False)[display_cols].head(10))

print("\n--- Top 10 Players the Model OVERESTIMATED (Predicted too high) ---")
print(biggest_misses.sort_values('residual_error', ascending=True)[display_cols].head(10))


model2_df.head()


#Country of citizenship and birth were some big indicators, but objectively they should not effect true player value, lets try taking them out
model3_df = model2_df.drop(columns=['country_of_birth', 'country_of_citizenship'])


numerical_features = ['height_in_cm', 'contract_days_remaining', 'yellow_cards',
                      'goals', 'assists', 'minutes_played', 'red_cards', 'club_1', 
                      'club_2', 'club_3', 'club_4', 'club_5', 'club_6', 'club_7', 
                      'club_8', 'club_9', 'club_10', 'club_11', 'club_12', 
                      'club_13', 'age', 'age_peak_diff_sq', 'goals_per_90', 
                      'assists_per_90','goals_adjusted', 'assists_adjusted', 
                      'minutes_played_adjusted'
                     ]

categorical_features = ['sub_position', 'position', 'foot', 
                        'current_club_domestic_competition_id','contract_info_missing'
                       ]
                        
X = model3_df.drop('market_value_in_eur', axis=1)
y = model3_df['market_value_in_eur']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

xgb_pipeline4, xgb_r2, xgb_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=False
)

xgb_pipeline4_log, xgb_r2_log, xgb_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=True
)





stats_df.head()


competitions_df.head()


competitions_df['country_name'].unique()


competitions_df['type'].unique()


competitions_df[competitions_df['type'] == 'other']


competitions_df[competitions_df['type'] == 'international_cup']['name']


#Map by country (coefficient score from UEFA)
country_value_map = {
    'England': 90.839,
    'Spain': 74.953,
    'Germany': 71.117,
    'Italy': 80.946,
    'France': 65.177,
    'Portugal': 52.766,
    'Netherlands': 58.116,
    'Belgium': 51.150,
    'Turkey': 41,
    'Russia': 18.299,
    'Greece': 34.412,
    'Ukraine': 18.475,
    'Denmark': 30.481,
    'Scotland': 26.125
}

competitions_df['country_score'] = competitions_df['country_name'].map(country_value_map)


#My own weights based off domain knowledge, relative to country score
int_map =  {
    'uefa-super-cup': 75,
    'europa-league': 80,
    'uefa-conference-league': 65,
    'europa-league-qualifikation': 55,
    'uefa-europa-conference-league-qualifikation': 45,
    'uefa-champions-league': 115,
    'uefa-champions-league-qualifikation': 65
}

competitions_df['int_score'] = competitions_df['name'].map(int_map)

# Define list of conditions
conditions = [
    competitions_df['type'] == 'domestic_cup',
    competitions_df['type'] == 'domestic_league',
    competitions_df['type'] == 'other',
    competitions_df['type'] == 'international_cup'
]

# Define the list of choices that correspond to each condition
choices = [
    competitions_df['country_score'] * 0.75,
    competitions_df['country_score'],
    competitions_df['country_score'] * 0.5,
    competitions_df['int_score']
]

# 3. Create the new column using np.select
# The 'default' value is used if none of the conditions are met.
competitions_df['comp_score'] = np.select(conditions, choices, default=0)


#Fix KLUB competition
competitions_df['comp_score'] = competitions_df['comp_score'].fillna(55)


competitions_df[['name', 'comp_score']].sort_values('comp_score',ascending=False)


#Normalize comp_score before adjusting goals, etc
competitions_df['normal_score'] = norm_scaler.fit_transform(competitions_df[['comp_score']])


stats_df = pd.merge(
    left=stats_df, 
    right=competitions_df[['normal_score', 'competition_id']],
    on='competition_id',
    how='left'
)


stats_df.head()


# List of the already-adjusted columns to further adjust
adjusted_cols = ['goals_adjusted', 'assists_adjusted', 'minutes_played_adjusted']

# Loop through each column and multiply by the competition score
for col in adjusted_cols:
    stats_df[col] = stats_df[col] * stats_df['normal_score']

stats_df.head()


model2_df.head()


weighted_new = stats_df.groupby('player_id')[['goals_adjusted', 'assists_adjusted', 'minutes_played_adjusted']].sum()

weighted_new = weighted_new.reset_index()


weighted_new


model5_df = pd.merge(
    left=model5_df, 
    right=weighted_new,
    on='player_id',
    how='left'
)


model5_df.columns


model5_df = model5_df.drop(columns=['normal_wins', 'goals_adjusted_x','assists_adjusted_x', 'minutes_played_adjusted_x','agent_name'])
model5_with_id = model5_df.copy()
model5_df = model5_df.drop(columns=['player_id'])
model5_df.head()


numerical_features = ['height_in_cm', 'contract_days_remaining', 'yellow_cards',
                      'goals', 'assists', 'minutes_played', 'red_cards', 'club_1', 
                      'club_2', 'club_3', 'club_4', 'club_5', 'club_6', 'club_7', 
                      'club_8', 'club_9', 'club_10', 'club_11', 'club_12', 
                      'club_13', 'age', 'age_peak_diff_sq', 'goals_per_90', 
                      'assists_per_90','goals_adjusted_y', 'assists_adjusted_y', 
                      'minutes_played_adjusted_y'
                     ]

categorical_features = ['country_of_birth', 'country_of_citizenship', 'sub_position', 
                        'position', 'foot', 'current_club_domestic_competition_id',
                        'contract_info_missing'
                       ]
                        
X = model5_df.drop('market_value_in_eur', axis=1)
y = model5_df['market_value_in_eur']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

xgb_pipeline5, xgb_r2, xgb_rmse = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=False
)

xgb_pipeline5_log, xgb_r2_log, xgb_rmse_log = fit_evaluate_and_tune_model(
    X_train, X_test, y_train, y_test, XGBRegressor, numerical_features, categorical_features, log_transform_target=True
)





# 1. Access the trained XGBoost model and the preprocessor from the pipeline
xgb_model = xgb_pipeline5.named_steps['regressor']
preprocessor = xgb_pipeline5.named_steps['preprocessor']

# 2. Get the feature names after all transformations (like one-hot encoding)
# This is crucial for matching the scores to the correct feature names
feature_names = preprocessor.get_feature_names_out()

# 3. Get the feature importance scores from the model
importances = xgb_model.feature_importances_

# 4. Create a pandas Series for easy viewing and sorting
feature_importance_series = pd.Series(importances, index=feature_names)

# 5. Sort the values to see the most important features at the top
print("--- Top 15 Most Important Features (from XGBoost) ---")
print(feature_importance_series.nlargest(15))

# --- 1. Prepare Data for Analysis --
# Make predictions on the test set
y_pred = xgb_pipeline5.predict(X_test)

y_pred_eur = y_pred
y_test_eur = y_test

# Create a new DataFrame for analysis to avoid SettingWithCopyWarning
analysis_df = X_test.copy()
analysis_df['actual_market_value'] = y_test_eur
analysis_df['predicted_market_value'] = y_pred_eur
analysis_df['residual_error'] = analysis_df['actual_market_value'] - analysis_df['predicted_market_value']


# --- 2. Analyze the Residuals (Plotting) ---
# A residual plot shows the errors vs. a feature

plt.figure(figsize=(12, 7))
sns.scatterplot(x='age', y='residual_error', data=analysis_df, alpha=0.5)
plt.axhline(0, color='red', linestyle='--')
plt.title('Residual Error vs. Player Age', fontsize=16)
plt.xlabel('Player Age (Years)', fontsize=12)
plt.ylabel('Prediction Error (Actual - Predicted) in EUR', fontsize=12)
plt.grid(True)
plt.show()


# --- 3. Examine the Biggest Misses ---
analysis_df = analysis_df.merge(players_df[['name']], left_index=True, right_index=True, how='left')

# Sort by the absolute error to find the biggest misses overall
analysis_df['abs_error'] = analysis_df['residual_error'].abs()
biggest_misses = analysis_df.sort_values('abs_error', ascending=False)

# Display the top 20 biggest prediction errors
print("--- Top 20 Biggest Prediction Misses ---")
display_cols = ['name', 'age', 'actual_market_value', 'predicted_market_value', 'residual_error']
print(biggest_misses[display_cols].head(20))


print("\n--- Top 10 Players the Model UNDERESTIMATED (Predicted too low) ---")
print(biggest_misses.sort_values('residual_error', ascending=False)[display_cols].head(10))

print("\n--- Top 10 Players the Model OVERESTIMATED (Predicted too high) ---")
print(biggest_misses.sort_values('residual_error', ascending=True)[display_cols].head(10))


from sklearn.cluster import KMeans
from sklearn.pipeline import Pipeline

# --- 1. Select and Prepare the Data ---
numerical_features = [
    'height_in_cm', 'contract_days_remaining', 'yellow_cards',
    'goals', 'assists', 'minutes_played', 'red_cards', 'club_1',
    'club_2', 'club_3', 'club_4', 'club_5', 'club_6', 'club_7',
    'club_8', 'club_9', 'club_10', 'club_11', 'club_12',
    'club_13', 'age', 'age_peak_diff_sq', 'goals_per_90',
    'assists_per_90','goals_adjusted_y', 'assists_adjusted_y',
    'minutes_played_adjusted_y'
]

# Create a new DataFrame with only the features for clustering
cluster_df = model5_df[numerical_features].copy()

# --- 2. Create a Preprocessing Pipeline ---
# K-Means requires data to be scaled and have no missing values.
# The imputer handles any NaNs, and the scaler standardizes the features.
preprocessing_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Apply the preprocessing to your data
X_processed = preprocessing_pipeline.fit_transform(cluster_df)


# --- 3. Find the Optimal Number of Clusters (k) using the Elbow Method ---
# We calculate the inertia (sum of squared distances to the closest centroid)
# for a range of k values. The "elbow" point is the optimal k.
inertia_scores = []
k_range = range(2, 50) # Test k from 2 to 10 clusters

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_processed)
    inertia_scores.append(kmeans.inertia_)

# Plot the Elbow Curve
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia_scores, marker='o', linestyle='--')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')
plt.grid(True)
plt.show()


# --- 4. Fit the Final K-Means Model ---
# Based on the elbow plot, choose the optimal number of clusters. We can probably go beyond 10 and still get meaningful distinction, but too many starts to create very specific categories
optimal_k = 10
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
kmeans_final.fit(X_processed)

# Add the cluster labels back to your original DataFrame
model5_with_id['cluster'] = kmeans_final.labels_
print(f"\nSuccessfully assigned players to {optimal_k} clusters.")


# --- 5. Analyze the Clusters ---
# Calculate the mean of the features for each cluster to understand their characteristics.
cluster_summary = model5_with_id.groupby('cluster')[numerical_features].mean().round(2)

print("\n--- Cluster Summary (Average Stats per Cluster) ---")
# Transposing (.T) often makes the summary easier to read
print(cluster_summary.T)





full_predict5 = xgb_pipeline5.predict(model5_df)


cluster_counts = model5_with_id['cluster'].value_counts()
cluster_counts


model5_with_id[model5_with_id['cluster'] == 4]


players_df[players_df['player_id'] == 181477]


# --- Find Outliers in Each Cluster ---
model5_with_id['predicted_market_value'] = full_predict5

# Calculate the z-score for each player's market value within their cluster.
# A high z-score (e.g., > 2.5) indicates an outlier.
model5_with_id['value_zscore'] = model5_with_id.groupby('cluster')['market_value_in_eur'].transform(
    lambda x: (x - x.mean()) / x.std()
)

model5_with_id['predict_zscore'] = model5_with_id.groupby('cluster')['predicted_market_value'].transform(
    lambda x: (x - x.mean()) / x.std()
)

# Sort by the z-score to find the biggest outliers
outliers_df = model5_with_id.sort_values('value_zscore', ascending=False)

# Display the top 50 most overvalued players relative to their cluster peers
print("\n--- Top 50 Outliers (Most Valuable vs. Cluster Average) ---")
display_cols = ['name', 'cluster', 'market_value_in_eur', 'value_zscore', 'predicted_market_value', 'predict_zscore']
outliers_df = pd.merge(left=outliers_df, right=players_df[['player_id', 'name']], on='player_id', how='left')
outliers_df[display_cols].head(50)


outliers_df[display_cols].sort_values('predict_zscore', ascending=False).head(50)


outliers_df['diff'] = outliers_df['predict_zscore'] - outliers_df['value_zscore']

outliers_df[display_cols + ['diff']].sort_values('diff', ascending=False).head(20)





outliers_df[['name', 'diff']].sort_values('diff', ascending=False).head(20)



